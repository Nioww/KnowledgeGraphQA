{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer,get_custom_objects\n",
    "import codecs\n",
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model,load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7681536765323704628\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3127299276\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18359831461309078996\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 20\n",
    "config_path = r'D:\\final_design\\Final_one\\bert\\bert_config.json'\n",
    "checkpoint_path = r'D:\\final_design\\Final_one\\bert\\bert_model.ckpt'\n",
    "dict_path = r'D:\\final_design\\Final_one\\bert\\vocab.txt'\n",
    "\n",
    "corpus_path = r'C:\\Users\\HashiriNio\\Desktop\\lcqmc-NLP\\lcqmc_train.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "    for line in reader:\n",
    "        token = line.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx1 = []\n",
    "trainx2 = []\n",
    "trainy = []\n",
    "with codecs.open(corpus_path, 'r', 'utf8') as reader:\n",
    "    for i in reader:\n",
    "        trainx1.append(i.split('\\t')[0])\n",
    "        trainx2.append(i.split('\\t')[1])\n",
    "        trainy.append(i.split('\\t')[2].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx1 = trainx1[1:]\n",
    "trainx2 = trainx2[1:]\n",
    "trainy = trainy[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(seq1,seq2):\n",
    "    X1_1,X1_2,X2_1,X2_2 = [] ,[],[],[]\n",
    "    for i in range(len(seq1)):\n",
    "        x1_1,x1_2 = tokenizer.encode(first = seq1[i],max_len = max_seq_len)\n",
    "        x2_1,x2_2 = tokenizer.encode(first = seq2[i],max_len = max_seq_len)\n",
    "        X1_1.append(x1_1)\n",
    "        X1_2.append(x1_2)\n",
    "        X2_1.append(x2_1)\n",
    "        X2_2.append(x2_2)\n",
    "    return np.array(X1_1), np.array(X1_2), np.array(X2_1), np.array(X2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_1,train1_2,train2_1,train2_2 = get_tokens(trainx1,trainx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_7 (Functional)            (None, None, 768)    101677056   input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 768)          0           model_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (None, 768)          0           model_7[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract_3 (TFOpLambda) (None, 768)          0           tf.__operators__.getitem_6[0][0] \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.abs_3 (TFOpLambda)      (None, 768)          0           tf.math.subtract_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_3 (TFOpLambda)        (None, 2304)         0           tf.__operators__.getitem_6[0][0] \n",
      "                                                                 tf.__operators__.getitem_7[0][0] \n",
      "                                                                 tf.math.abs_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2304)         0           tf.concat_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            1026        dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 102,858,242\n",
      "Trainable params: 1,181,186\n",
      "Non-trainable params: 101,677,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "#    def lr(y_true, y_pred):\n",
    "#        return optimizer.lr\n",
    "#    return lr\n",
    "\n",
    "#optimizer = Adam(lr=1e-4)  \n",
    "#lr_metric = get_lr_metric(optimizer)\n",
    "\n",
    "\n",
    "bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)\n",
    "drop_out_rate = 0.5\n",
    "dense_layer = 512\n",
    "class_num = 2\n",
    "#for l in bert_model.layers:\n",
    "#    l.trainable = True\n",
    "\n",
    "x1_1_in = Input(shape=(None,))\n",
    "x1_2_in = Input(shape=(None,))\n",
    "x2_1_in = Input(shape=(None,))\n",
    "x2_2_in = Input(shape=(None,))\n",
    "\n",
    "\n",
    "x1 = bert_model([x1_1_in, x1_2_in])\n",
    "x2 = bert_model([x2_1_in, x2_2_in])\n",
    "Lambda= lambda x: x[:, 0]\n",
    "x1 = Lambda(x1)\n",
    "x2 = Lambda(x2)\n",
    "\n",
    "concat_layer = tf.concat((x1,x2,tf.abs(tf.math.subtract(x1, x2))),1)\n",
    "drop_out = tf.keras.layers.Dropout(drop_out_rate)(concat_layer)\n",
    "Dense_l = Dense(dense_layer,activation='relu')(drop_out)\n",
    "output = Dense(class_num,activation='softmax')(Dense_l)\n",
    "\n",
    "model = Model([x1_1_in,x1_2_in,x2_1_in,x2_2_in], output)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.save(r'D:\\final_design\\Final_one\\data\\model\\model_match_general5.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects as gt_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-0b53280228a2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-44-0b53280228a2>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    get_custom_objects.update({'lr_metric': lr_metric,'gelu': <function gelu at 0x0000026AAFCC59D8>, 'LayerNormalization': <class 'keras_layer_normalization.layer_normalization.LayerNormalization'>, 'MultiHeadAttention': <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'>, 'FeedForward': <class 'keras_position_wise_feed_forward.feed_forward.FeedForward'>, 'TrigPosEmbedding': <class 'keras_pos_embd.trig_pos_embd.TrigPosEmbedding'>, 'EmbeddingRet': <class 'keras_embed_sim.embeddings.EmbeddingRet'>, 'EmbeddingSim': <class 'keras_embed_sim.embeddings.EmbeddingSim'>, 'PositionEmbedding': <class 'keras_pos_embd.pos_embd.PositionEmbedding'>, 'TokenEmbedding': <class 'keras_bert.layers.embedding.TokenEmbedding'>, 'EmbeddingSimilarity': <class 'keras_bert.layers.embedding.EmbeddingSimilarity'>, 'TaskEmbedding': <class 'keras_bert.layers.task_embed.TaskEmbedding'>, 'Masked': <class 'keras_bert.layers.masked.Masked'>, 'Extract': <class 'keras_bert.layers.extract.Extract'>, 'AdamWarmup': <class 'keras_bert.optimizers.warmup_v2.AdamWarmup'>})\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "{'lr_metric': lr_metric,'gelu': <function gelu at 0x0000026AAFCC59D8>, 'LayerNormalization': <class 'keras_layer_normalization.layer_normalization.LayerNormalization'>, 'MultiHeadAttention': <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'>, 'FeedForward': <class 'keras_position_wise_feed_forward.feed_forward.FeedForward'>, 'TrigPosEmbedding': <class 'keras_pos_embd.trig_pos_embd.TrigPosEmbedding'>, 'EmbeddingRet': <class 'keras_embed_sim.embeddings.EmbeddingRet'>, 'EmbeddingSim': <class 'keras_embed_sim.embeddings.EmbeddingSim'>, 'PositionEmbedding': <class 'keras_pos_embd.pos_embd.PositionEmbedding'>, 'TokenEmbedding': <class 'keras_bert.layers.embedding.TokenEmbedding'>, 'EmbeddingSimilarity': <class 'keras_bert.layers.embedding.EmbeddingSimilarity'>, 'TaskEmbedding': <class 'keras_bert.layers.task_embed.TaskEmbedding'>, 'Masked': <class 'keras_bert.layers.masked.Masked'>, 'Extract': <class 'keras_bert.layers.extract.Extract'>, 'AdamWarmup': <class 'keras_bert.optimizers.warmup_v2.AdamWarmup'>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_custom_objects().update({'lr':lr_metric})\n",
    "gt_custom_objects().update(get_custom_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_custom_objects().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': <function get_lr_metric.<locals>.lr at 0x000001CE93B53318>, 'gelu': <function gelu at 0x000001CE12DB5AF8>, 'LayerNormalization': <class 'keras_layer_normalization.layer_normalization.LayerNormalization'>, 'MultiHeadAttention': <class 'keras_multi_head.multi_head_attention.MultiHeadAttention'>, 'FeedForward': <class 'keras_position_wise_feed_forward.feed_forward.FeedForward'>, 'TrigPosEmbedding': <class 'keras_pos_embd.trig_pos_embd.TrigPosEmbedding'>, 'EmbeddingRet': <class 'keras_embed_sim.embeddings.EmbeddingRet'>, 'EmbeddingSim': <class 'keras_embed_sim.embeddings.EmbeddingSim'>, 'PositionEmbedding': <class 'keras_pos_embd.pos_embd.PositionEmbedding'>, 'TokenEmbedding': <class 'keras_bert.layers.embedding.TokenEmbedding'>, 'EmbeddingSimilarity': <class 'keras_bert.layers.embedding.EmbeddingSimilarity'>, 'TaskEmbedding': <class 'keras_bert.layers.task_embed.TaskEmbedding'>, 'Masked': <class 'keras_bert.layers.masked.Masked'>, 'Extract': <class 'keras_bert.layers.extract.Extract'>, 'AdamWarmup': <class 'keras_bert.optimizers.warmup_v2.AdamWarmup'>}\n"
     ]
    }
   ],
   "source": [
    "print(gt_custom_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'D:\\final_design\\Final_one\\data\\model\\model_match_general5.h5',custom_objects=get_custom_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "optimizer = Adam(lr=1e-4)  \n",
    "lr_metric = get_lr_metric(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=6.25e-06>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5, patience=6, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 213s 455ms/step - loss: 0.5093 - accuracy: 0.7531 - val_loss: 0.4530 - val_accuracy: 0.7950\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 217s 462ms/step - loss: 0.5106 - accuracy: 0.7538 - val_loss: 0.4549 - val_accuracy: 0.7870\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 219s 468ms/step - loss: 0.5116 - accuracy: 0.7513 - val_loss: 0.4533 - val_accuracy: 0.7930\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 219s 468ms/step - loss: 0.5112 - accuracy: 0.7539 - val_loss: 0.4539 - val_accuracy: 0.7890\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 219s 466ms/step - loss: 0.5107 - accuracy: 0.7505 - val_loss: 0.4557 - val_accuracy: 0.7870\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 218s 465ms/step - loss: 0.5096 - accuracy: 0.7551 - val_loss: 0.4548 - val_accuracy: 0.7900\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 218s 465ms/step - loss: 0.5086 - accuracy: 0.7498 - val_loss: 0.4567 - val_accuracy: 0.7900\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 218s 464ms/step - loss: 0.5109 - accuracy: 0.7506 - val_loss: 0.4552 - val_accuracy: 0.7890\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 218s 465ms/step - loss: 0.5122 - accuracy: 0.7512 - val_loss: 0.4554 - val_accuracy: 0.7910\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 218s 465ms/step - loss: 0.5074 - accuracy: 0.7526 - val_loss: 0.4558 - val_accuracy: 0.7900\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1.5625e-06>\n"
     ]
    }
   ],
   "source": [
    "p = 60000\n",
    "p2 = p+30000\n",
    "#epoch = 4\n",
    "\n",
    "model.fit([train1_1[p:p2],train1_2[p:p2],train2_1[p:p2],train2_2[p:p2]],trainy[p:p2], epochs=10, batch_size=64,validation_data = ([train1_1[200000:201000],train1_2[200000:201000],train2_1[200000:201000],train2_2[200000:201000]],trainy[200000:201000]),callbacks=[reduce_lr],shuffle=True)\n",
    "print(model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'D:\\final_design\\Final_one\\data\\model\\model_match_general5_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss: 0.5221 - accuracy: 0.7422 - val_loss: 0.4793 - val_accuracy: 0.7850 \n",
    "#loss: 0.4933 - accuracy: 0.7630 - val_loss: 0.4689 - val_accuracy: 0.7880\n",
    "# loss: 0.5147 - accuracy: 0.7512 - val_loss: 0.4606 - val_accuracy: 0.7940\n",
    "#loss: 0.5179 - accuracy: 0.7468 - val_loss: 0.4564 - val_accuracy: 0.7900\n",
    "#loss: 0.5074 - accuracy: 0.7526 - val_loss: 0.4558 - val_accuracy: 0.7900\n",
    "\n",
    "#（1）val_loss: 0.5682 - val_accuracy: 0.7600    （2)val_loss: 0.5611 - val_accuracy: 0.7680 \n",
    "#(3)val_loss: 0.4719 - val_accuracy: 0.7850       (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = 2000\n",
    "m2 = 4000\n",
    "#loss: 0.7122 - accuracy: 0.5740\n",
    "#loss: 0.6911 - accuracy: 0.5997\n",
    "#loss: 0.6421 - accuracy: 0.6437\n",
    "#loss: 0.6079 - accuracy: 0.6761\n",
    "#loss: 0.6023 - accuracy: 0.6830\n",
    "#loss: 0.5837 - accuracy: 0.6894\n",
    "#loss: 0.5724 - accuracy: 0.7027\n",
    "#loss: 0.5606 - accuracy: 0.7077\n",
    "#loss: 0.5576 - accuracy: 0.7178\n",
    "#loss: 0.5492 - accuracy: 0.7239  (56000:66000\n",
    "#loss: 0.5347 - accuracy: 0.7272\n",
    "#loss: 0.5191 - accuracy: 0.7458"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = [int(x) for x in trainy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = [[0,1] if x == 0 else [1,0] for x in trainy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy = np.array(trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238766"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train1_1)\n",
    "#8000（0.5960  \n",
    "#训练进程：2000:4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_13 (Functional)           (None, None, 768)    101677056   input_17[0][0]                   \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_11 (Sl (None, 768)          0           model_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_12 (Sl (None, 768)          0           model_13[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_26 (TFOpLambda)  (None, 1, 768)       0           tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_27 (TFOpLambda)  (None, 768, 1)       0           tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_28 (TFOpLambda)  (None, 1, 768)       0           tf.__operators__.getitem_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_29 (TFOpLambda)  (None, 768, 1)       0           tf.__operators__.getitem_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_13 (TFOpLambda (None, 1, 1)         0           tf.expand_dims_26[0][0]          \n",
      "                                                                 tf.expand_dims_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_14 (TFOpLambda (None, 1, 1)         0           tf.expand_dims_28[0][0]          \n",
      "                                                                 tf.expand_dims_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_13 (TFOpLa (None, 1)            0           tf.linalg.matmul_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_14 (TFOpLa (None, 1)            0           tf.linalg.matmul_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) (None, 1)            0           tf.compat.v1.squeeze_13[0][0]    \n",
      "                                                                 tf.compat.v1.squeeze_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_24 (TFOpLambda)  (None, 1, 768)       0           tf.__operators__.getitem_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims_25 (TFOpLambda)  (None, 768, 1)       0           tf.__operators__.getitem_12[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf.clip_by_value_4 (TFOpLambda) (None, 1)            0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.linalg.matmul_12 (TFOpLambda (None, 1, 1)         0           tf.expand_dims_24[0][0]          \n",
      "                                                                 tf.expand_dims_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sqrt_4 (TFOpLambda)     (None, 1)            0           tf.clip_by_value_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_12 (TFOpLa (None, 1)            0           tf.linalg.matmul_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.maximum_4 (TFOpLambda)  (None, 1)            0           tf.math.sqrt_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv_4 (TFOpLambda)  (None, 1)            0           tf.compat.v1.squeeze_12[0][0]    \n",
      "                                                                 tf.math.maximum_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            2           tf.math.truediv_4[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 101,677,058\n",
      "Trainable params: 2\n",
      "Non-trainable params: 101,677,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from keras.layers.core import Lambda\n",
    "#'''\n",
    "bert_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, seq_len=None)\n",
    "drop_out_rate = 0.2\n",
    "dense_layer = 512\n",
    "class_num = 1\n",
    "#for l in bert_model.layers:\n",
    "#    l.trainable = True\n",
    "\n",
    "x1_1_in = Input(shape=(None,))\n",
    "x1_2_in = Input(shape=(None,))\n",
    "x2_1_in = Input(shape=(None,))\n",
    "x2_2_in = Input(shape=(None,))\n",
    "\n",
    "\n",
    "x1 = bert_model([x1_1_in, x1_2_in])\n",
    "x2 = bert_model([x2_1_in, x2_2_in])\n",
    "Lambda= lambda x: x[:, 0]\n",
    "x1 = Lambda(x1)\n",
    "x2 = Lambda(x2)\n",
    "#print(x1[0].shape)\n",
    "\n",
    "dropl = tf.keras.layers.Dropout(drop_out_rate)\n",
    "drop_out_1 = dropl(x1)\n",
    "drop_out_2 = dropl(x2)\n",
    "#Dense_l = Dense(dense_layer,activation='relu')\n",
    "#m1 = Dense_l(drop_out_1)\n",
    "#m2 = Dense_l(drop_out_2)\n",
    "#cosinelayer = CosineLayer()\n",
    "#intern = cosinelayer(x1,x2)\n",
    "output = Dense(class_num,activation='sigmoid')(intern)\n",
    "\n",
    "model = Model([x1_1_in,x1_2_in,x2_1_in,x2_2_in], output)\n",
    "model.compile(loss='binary_crossentropy',optimizer=Adam(1e-5),metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.save(r'D:\\final_design\\Final_one\\data\\model\\model_match_general_2.h5')\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-537b4c3b5e0a>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "        cuda_only=False,\n",
    "        min_cuda_compute_capability=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 6427, 6241, 3563, 1798, 102, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "text = '语言模型'\n",
    "tokens = tokenizer.tokenize(text)\n",
    "# ['[CLS]', '语', '言', '模', '型', '[SEP]']\n",
    "indices, segments = tokenizer.encode(first=text, max_len=512)\n",
    "print(indices[:10])\n",
    "print(segments[:10])\n",
    "\n",
    "model = load_trained_model_from_checkpoint(config_path, checkpoint_path)\n",
    "predicts = model.predict([np.array([indices]), np.array([segments])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lambda= lambda x: x[:, 1]\n",
    "x1 = Lambda(predicts)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "#from keras.layers.core import Lambda\n",
    "\n",
    "class CosineLayer():\n",
    "\n",
    "    def __call__(self, x1, x2):\n",
    "\n",
    "        def _cosine(x):\n",
    "            dot1 = K.batch_dot(x[0], x[1], axes=1)\n",
    "            dot2 = K.batch_dot(x[0], x[0], axes=1)\n",
    "            dot3 = K.batch_dot(x[1], x[1], axes=1)\n",
    "            max_ = K.maximum(K.sqrt(dot2 * dot3), K.epsilon())\n",
    "            return dot1 / max_\n",
    "\n",
    "        #output_shape = (1,)\n",
    "        Lambda = lambda x :_cosine(x)\n",
    "        value = Lambda([x1, x2])\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot do batch_dot on inputs with rank < 2. Received inputs with shapes (6,) and (6,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-53a3797d2345>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCosineLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-58234f860384>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#output_shape = (1,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mLambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0m_cosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-58234f860384>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#output_shape = (1,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mLambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0m_cosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-58234f860384>\u001b[0m in \u001b[0;36m_cosine\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_cosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mdot1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mdot2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mdot3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_dot\u001b[1;34m(x, y, axes)\u001b[0m\n\u001b[0;32m   1958\u001b[0m                      \u001b[1;34m'Received inputs with shapes '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' and '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m                      str(y_shape) + '.')\n\u001b[0m\u001b[0;32m   1961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m   \u001b[0mx_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot do batch_dot on inputs with rank < 2. Received inputs with shapes (6,) and (6,)."
     ]
    }
   ],
   "source": [
    "x1 = np.array([1,2,3,4,5,6])\n",
    "x2 = np.array([5,1,3,4,8,6])\n",
    "k = CosineLayer()\n",
    "m = k(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921328669759435"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "path = r'D:\\final_design\\Final_one\\data\\model\\model_match_general%d.h5'%i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\final_design\\\\Final_one\\\\data\\\\model\\\\model_match_general5.h5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to Python 3.7's help utility!\n",
      "\n",
      "If this is your first time using Python, you should definitely check out\n",
      "the tutorial on the Internet at https://docs.python.org/3.7/tutorial/.\n",
      "\n",
      "Enter the name of any module, keyword, or topic to get help on writing\n",
      "Python programs and using Python modules.  To quit this help utility and\n",
      "return to the interpreter, just type \"quit\".\n",
      "\n",
      "To get a list of available modules, keywords, symbols, or topics, type\n",
      "\"modules\", \"keywords\", \"symbols\", or \"topics\".  Each module also comes\n",
      "with a one-line summary of what it does; to list the modules whose name\n",
      "or summary contain a given string such as \"spam\", type \"modules spam\".\n",
      "\n",
      "help> keras_bert.get_custom_objects\n",
      "Help on function get_custom_objects in keras_bert:\n",
      "\n",
      "keras_bert.get_custom_objects = get_custom_objects()\n",
      "    Get all custom objects for loading saved models.\n",
      "\n",
      "help> quit\n",
      "\n",
      "You are now leaving help and returning to the Python interpreter.\n",
      "If you want to ask for help on a particular object directly from the\n",
      "interpreter, you can type \"help(object)\".  Executing \"help('string')\"\n",
      "has the same effect as typing a particular string at the help> prompt.\n"
     ]
    }
   ],
   "source": [
    "help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
