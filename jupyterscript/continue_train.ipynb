{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras_bert import load_trained_model_from_checkpoint, Tokenizer,get_custom_objects\n",
    "import codecs\n",
    "from keras.layers import Input,Dense,LSTM\n",
    "from keras.layers.wrappers import TimeDistributed,Bidirectional\n",
    "from keras.models import Model,load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2297, 20)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 20\n",
    "config_path = r'D:\\final_design\\Final_one\\bert\\bert_config.json'\n",
    "checkpoint_path = r'D:\\final_design\\Final_one\\bert\\bert_model.ckpt'\n",
    "dict_path = r'D:\\final_design\\Final_one\\bert\\vocab.txt'\n",
    "\n",
    "train_corpus = pickle.load(open(r'D:\\final_design\\Final_one\\data\\corpus_train.pkl','rb'))\n",
    "train_questions = [train_corpus[i]['question'] for i in range(len(train_corpus))]\n",
    "train_entitys = [train_corpus[i]['gold_entitys'] for i in range(len(train_corpus))]\n",
    "train_entitys = [[entity[1:-1].split('_')[0] for entity in line]for line in train_entitys]\n",
    "\n",
    "test_corpus = pickle.load(open(r'D:\\final_design\\Final_one\\data\\corpus_test.pkl','rb'))\n",
    "test_questions = [test_corpus[i]['question'] for i in range(len(test_corpus))]\n",
    "test_entitys = [test_corpus[i]['gold_entitys'] for i in range(len(test_corpus))]\n",
    "test_entitys = [[entity[1:-1].split('_')[0] for entity in line]for line in test_entitys]\n",
    "\n",
    "\n",
    "token_dict = {}\n",
    "with codecs.open(dict_path,'r','utf-8') as f:\n",
    "    for i in f:\n",
    "        token = i.strip()\n",
    "        token_dict[token] = len(token_dict)\n",
    "tokenizer = Tokenizer(token_dict)\n",
    "\n",
    "def setlabel(question,entity):\n",
    "    m=np.zeros((len(question)+1,len(entity)+1),int) #生成0矩阵，为方便后续计算，比字符串长度多了一列\n",
    "    mmax=0  #最长匹配的长度\n",
    "    p=0 #最长匹配对应在question中的最后一位\n",
    "    for i in range(len(question)):\n",
    "        for j in range(len(entity)):\n",
    "            if question[i]==entity[j]:\n",
    "                m[i+1][j+1]=m[i][j]+1\n",
    "            if m[i+1][j+1]>mmax:\n",
    "                mmax=m[i+1][j+1]\n",
    "                p=i+1\n",
    "    #print(question,entity,p,mmax)\n",
    "    return question[p-mmax:p]\n",
    "\n",
    "def getPair(questions, entitys):\n",
    "    X, X2, Y = [], [], []\n",
    "    for i in range(len(questions)):\n",
    "        q = questions[i]\n",
    "        x, x2 = tokenizer.encode(first=q,max_len = max_seq_len)#词索引序列和分块索引序列\n",
    "        y = [[0] for j in range(max_seq_len)]\n",
    "        assert len(x)==len(y)\n",
    "        for e in entitys[i]:\n",
    "            #得到实体名和问题的最长连续公共子串\n",
    "            e = setlabel(q,e)\n",
    "            if e in q:\n",
    "                begin = q.index(e)+1\n",
    "                end = begin + len(e)\n",
    "                if end < max_seq_len-1:\n",
    "                    for pos in range(begin,end):\n",
    "                        y[pos] = [1]\n",
    "        #print (q)\n",
    "        #print (x1)\n",
    "        #print (y)\n",
    "        X.append(x)\n",
    "        X2.append(x2)\n",
    "        Y.append(y)\n",
    "        #print(x2)\n",
    "    return np.array(X),np.array(X2),np.array(Y)\n",
    "\n",
    "\n",
    "#得到训练及测试样本\n",
    "trainx1,trainx2,trainy = getPair(train_questions,train_entitys)#(num_sample,max_len)\n",
    "testx1,testx2,testy = getPair(test_questions,test_entitys)\n",
    "print (trainx1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "model = load_model(r'D:\\final_design\\Final_one\\data\\model\\model_ner_general.h5',custom_objects=get_custom_objects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxf = 0.0\n",
    "def computeF(gold_entity,pre_entity):\n",
    "\n",
    "    #根据标注的实体位置和预测的实体位置，计算prf,完全匹配\n",
    "    #输入： Python-list  3D，值为每个实体的起始位置列表[begin，end]\n",
    "    #输出： float\n",
    "   \n",
    "    truenum = 0\n",
    "    prenum = 0\n",
    "    goldnum = 0\n",
    "    for i in range(len(gold_entity)):\n",
    "        goldnum += len(gold_entity[i])\n",
    "        prenum  += len(pre_entity[i])\n",
    "        truenum += len(set(gold_entity[i]).intersection(set(pre_entity[i])))\n",
    "    try:\n",
    "        precise = float(truenum) / float(prenum)\n",
    "        recall = float(truenum) / float(goldnum)\n",
    "        f = float(2 * precise * recall /( precise + recall)) \n",
    "    except:\n",
    "        precise = recall = f = 0.0\n",
    "    print('本轮实体的F值是 %f' %(f))\n",
    "    return precise,recall,f\n",
    "\n",
    "def restore_entity_from_labels_on_corpus(predicty,questions):\n",
    "    def restore_entity_from_labels(labels,question):\n",
    "        entitys = []\n",
    "        str = ''\n",
    "        labels = labels[1:-1]\n",
    "        #print(labels,question)\n",
    "        for i in range(min(len(labels),len(question))):\n",
    "            if labels[i]==1:\n",
    "                str += question[i]\n",
    "            else:\n",
    "                if len(str):\n",
    "                    entitys.append(str)\n",
    "                    str = ''\n",
    "        if len(str):\n",
    "            entitys.append(str) \n",
    "        return entitys\n",
    "    all_entitys = []\n",
    "    for i in range(len(predicty)):\n",
    "        all_entitys.append(restore_entity_from_labels(predicty[i],questions[i]))\n",
    "        #print(predicty[i])\n",
    "    return all_entitys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    model.fit([trainx1,trainx2],trainy, epochs=1,batch_size = 32)\n",
    "    predictys = model.predict([testx1,testx2],batch_size = 32)\n",
    "    predictys = [[1 if i >0.5 else 0 for i in line]for line in predictys]\n",
    "    k = restore_entity_from_labels_on_corpus(predictys,test_questions)\n",
    "    for m in range(200,220):\n",
    "        print('predict:',k[m])\n",
    "        print('true:',test_entitys[m])\n",
    "    p,r,f = computeF(test_entitys,k)\n",
    "    print('%d epoch,F is %.3f,precise is %.3f'%(i,f,p))\n",
    "    if f>maxf:\n",
    "        maxf = f\n",
    "        model.save(r'D:\\final_design\\Final_one\\data\\model\\model_ner_general.h5')\n",
    "        print('model updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r'D:\\final_design\\Final_one\\data\\model\\model_ner_general.h5',custom_objects=get_custom_objects())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "覆盖网络是指创建在其他网络之上的网络\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['覆盖网络', '创建在其他网络']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = '覆盖网络是指创建在其他网络之上的网络'\n",
    "i1,i2 = tokenizer.encode(first = q,max_len = max_seq_len)\n",
    "i1 = np.array(i1)\n",
    "i2 = np.array(i2)\n",
    "print(q)\n",
    "#print(i1,i2)\n",
    "#print(testx1[200],testx2[200])\n",
    "pre = model.predict([np.array([i1,i2]),np.array([i2,i2])])\n",
    "#print(pre[0])\n",
    "pre = [1 if i >0.5 else 0 for i in pre[0]]\n",
    "#print(pre)\n",
    "finl = restore_entity_from_labels_on_corpus([pre],[q])\n",
    "finl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxf = 0.0\n",
    "def computeF(gold_entity,pre_entity):\n",
    "\n",
    "    #根据标注的实体位置和预测的实体位置，计算prf,完全匹配\n",
    "    #输入： Python-list  3D，值为每个实体的起始位置列表[begin，end]\n",
    "    #输出： float\n",
    "   \n",
    "    truenum = 0\n",
    "    prenum = 0\n",
    "    goldnum = 0\n",
    "    for i in range(len(gold_entity)):\n",
    "        goldnum += len(gold_entity[i])\n",
    "        prenum  += len(pre_entity[i])\n",
    "        truenum += len(set(gold_entity[i]).intersection(set(pre_entity[i])))\n",
    "    try:\n",
    "        precise = float(truenum) / float(prenum)\n",
    "        recall = float(truenum) / float(goldnum)\n",
    "        f = float(2 * precise * recall /( precise + recall)) \n",
    "    except:\n",
    "        precise = recall = f = 0.0\n",
    "    print('本轮实体的F值是 %f' %(f))\n",
    "    return precise,recall,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,r,f = computeF(test_entitys,predict_entitys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
