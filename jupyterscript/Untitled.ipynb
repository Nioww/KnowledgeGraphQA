{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  8 14:40:24 2021\n",
    "\n",
    "@author: HashiriNio\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "#import pickle\n",
    "from keras_bert import Tokenizer, get_custom_objects\n",
    "import codecs as cs\n",
    "from keras.models import load_model\n",
    "from candidate_get import bridge\n",
    "\n",
    "\n",
    "class candi_scoring():\n",
    "    def __init__(self):\n",
    "        self.max_seq_len = 20\n",
    "        #åŠ è½½bertå­—å…¸\n",
    "        dict_path = r'D:\\final_design\\Final_one\\bert\\vocab.txt'\n",
    "        token_dict = {}\n",
    "        with cs.open(dict_path, 'r', 'utf8') as reader:\n",
    "            for line in reader:\n",
    "                token = line.strip()\n",
    "                token_dict[token] = len(token_dict)\n",
    "        self.tokenizer = Tokenizer(token_dict)\n",
    "        #åŠ è½½è¯„åˆ†æ¨¡å‹\n",
    "        self.model = load_model(r'D:\\final_design\\Final_one\\data\\model\\model_match_general5_1.h5',custom_objects=get_custom_objects())\n",
    "        print('loaded')\n",
    "    \n",
    "    def get_tokens(self, seq1, seq2):\n",
    "        #seq1ä¸ºstrï¼Œseq2ä¸ºlist\n",
    "        X1_1, X1_2, X2_1, X2_2 = [] ,[],[],[]\n",
    "        x1_1, x1_2 = self.tokenizer.encode(first = seq1, max_len = self.max_seq_len)\n",
    "        for i in range(len(seq2)):\n",
    "            #x1_1,x1_2 = self.tokenizer.encode(first = seq1[i],max_len = self.max_seq_len)\n",
    "            x2_1, x2_2 = self.tokenizer.encode(first = seq2[i], max_len = self.max_seq_len)\n",
    "            X1_1.append(x1_1)\n",
    "            X1_2.append(x1_2)\n",
    "            X2_1.append(x2_1)\n",
    "            X2_2.append(x2_2)\n",
    "        \n",
    "        return np.array(X1_1), np.array(X1_2), np.array(X2_1), np.array(X2_2)\n",
    "    \n",
    "    def get_ques(self, candidates):\n",
    "        #candidates = [(,),(,)]\n",
    "        candidate_paths = []\n",
    "        for candidate in candidates:\n",
    "            if len(candidate) == 2:\n",
    "                candidate_paths.append(candidate[0]+'çš„'+candidate[1]+'æ˜¯ï¼Ÿ')\n",
    "            else:\n",
    "                candidate_paths.append(candidate[0]+'çš„'+candidate[1]+'çš„'+candidate[2]+'æ˜¯ï¼Ÿ')\n",
    "        return candidate_paths\n",
    "    \n",
    "    def get_bridged_ques(self,paths):\n",
    "        # paths = [(x1,r1,r2,x2),()]\n",
    "        bridged_q = []\n",
    "        for path in paths:\n",
    "            bridged_q.append(path[0] + 'å’Œ' + path[3] + 'çš„ç›¸åŒç‚¹æ˜¯ï¼Ÿ')\n",
    "            bridged_q.append(path[0] + 'å’Œ' + path[3] + 'çš„åŒºåˆ«æ˜¯ï¼Ÿ')\n",
    "        return bridged_q\n",
    "\n",
    "    def scoring(self, question, candidates):\n",
    "        topk = 5\n",
    "        candidate_ques = self.get_ques(candidates)\n",
    "        in1_1, in1_2, in2_1, in2_2 = self.get_tokens(question, candidate_ques)\n",
    "        score = self.model.predict([in1_1, in1_2, in2_1, in2_2])\n",
    "        score1 = []\n",
    "        for i in score:\n",
    "            score1.append(i[0])\n",
    "        temp = sorted(score1, reverse=1)\n",
    "        Index = []\n",
    "        for i in range(min(topk, len(temp))):\n",
    "            Index.append(score1.index(temp[i]))\n",
    "        # æ¡¥æ¥æ‰“åˆ†\n",
    "        bridged_paths = bridge(Index, candidates)\n",
    "        # print('bridged_paths',bridged_paths)\n",
    "        if bridged_paths == []:\n",
    "            b_one = 0\n",
    "        else:\n",
    "            bridged_ques = self.get_bridged_ques(bridged_paths)  # é—®é¢˜æ•°ç›®æ˜¯è·¯å¾„çš„ä¸¤å€\n",
    "            # print('bridged_ques',bridged_ques)\n",
    "            in1_1, in1_2, in2_1, in2_2 = self.get_tokens(question, bridged_ques)\n",
    "            scoreb = self.model.predict([in1_1, in1_2, in2_1, in2_2])\n",
    "            print('æ¡¥æ¥å¾—åˆ†',scoreb)\n",
    "            score2 = []\n",
    "            for i in scoreb:\n",
    "                score2.append(i[0])\n",
    "            tempb = sorted(score2, reverse=1)\n",
    "            bindex = score2.index(tempb[0])\n",
    "            b_one = tempb[0]\n",
    "        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„è·¯å¾„\n",
    "        mark = 0\n",
    "        if b_one > score1[Index[0]]:\n",
    "            print(bindex / 2)\n",
    "            the_path = bridged_paths[int(bindex / 2)]\n",
    "            if bindex % 2 == 1:\n",
    "                mark = 1\n",
    "            the_score = b_one\n",
    "        else:\n",
    "            the_path = candidates[Index[0]]\n",
    "            the_score = score1[Index[0]]\n",
    "        return the_path, the_score, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#views.py\n",
    "import candidate_get\n",
    "\n",
    "# initiate\n",
    "entity_obtainer = EntityObtainer()\n",
    "scorer = candi_scoring()\n",
    "\n",
    "\n",
    "def qa(request):\n",
    "    count = Cal.objects.count()\n",
    "\n",
    "    if count != 0:\n",
    "        ques = request.POST['ques']\n",
    "        input_question = ques\n",
    "        entities = entity_obtainer.mention_get(input_question)\n",
    "        candidates = []\n",
    "        for entity in entities:\n",
    "            candidates += candidate_get.GetPaths(entity)\n",
    "        if candidates == []:\n",
    "            ans = 'æš‚æ—¶æ²¡æœ‰ä¹ å¾—ç›¸å…³çŸ¥è¯†ã€‚'\n",
    "        else:\n",
    "            the_path, the_score, mark = scorer.scoring(input_question, candidates)\n",
    "            print('æŸ¥è¯¢è·¯å¾„:', the_path, mark)\n",
    "            answer = candidate_get.get_answer(the_path, mark)\n",
    "            if the_score > 0.45:\n",
    "                print('ç­”æ¡ˆ:', answer, '\\nå¾—åˆ†:', str(the_score))\n",
    "                ans = answer\n",
    "            else:\n",
    "                ans = 'æˆ–è®¸æ¢ä¸ªé—®æ³•ä¼šæœ‰ç­”æ¡ˆï¼Ÿ'\n",
    "    else:\n",
    "        ques = '..'\n",
    "        ans = 'èŠœæ¹–!'\n",
    "\n",
    "    Cal.objects.create(question=ques, answer=ans, count=1)\n",
    "    record = Cal.objects.all()\n",
    "    return render(request, 'QAbot.html', context={'data': record})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls.py\n",
    "from django.contrib.staticfiles.urls import staticfiles_urlpatterns\n",
    "from django.contrib import staticfiles\n",
    "from django.contrib import admin\n",
    "from django.urls import path\n",
    "from myweb import views\n",
    "urlpatterns = [\n",
    "    path('admin/', admin.site.urls),\n",
    "    path('QAbot', views.qa),\n",
    "    #path('chat/', views.dd),\n",
    "]\n",
    "urlpatterns += staticfiles_urlpatterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QAbot\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ch\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>è®¡ç®—æœºç½‘ç»œQAbot</title>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<div id=\"container\" style=\"width:1020px\"><!-- container -->\n",
    "    <!-- å¤´éƒ¨ -->\n",
    "<div id=\"header\" style=\"background-color:#FFFFFF;\">\n",
    "<h1 style=\"margin-bottom:0;\">è®¡ç®—æœºç½‘ç»œQAbot</h1></div>\n",
    "    <!-- å·¦æ¡† -->\n",
    "<img src=\"/static/images/ki.jpg\" alt=\"ki\" height=450px width=320px style=\"float:left\">\n",
    " <!--<div id=\"menu\" style=\"background-image:url('ki.jpg');height:210px;width:100px;float:left;\">\n",
    "</div>-->\n",
    "    <!-- è®°å½•æ¡† -->\n",
    "\n",
    "<div id=\"content\" style=\"background-color:#EEEEEE;height:400px;width:700px;overflow:scroll; overflow-x:hidden; float:right;\">\n",
    "    {% for i in data %}\n",
    "<p>YOU:{{ i.question }}</p>\n",
    "<p>ROBOT:{{ i.answer }}</p>\n",
    "    {% endfor %}\n",
    "</div>\n",
    "\n",
    "    <!-- åˆ†å‰²çº¿ -->\n",
    "<div id=\"content\" style=\"background-color:#000000;height:1px;width:700px;float:right;\">\n",
    "</div>\n",
    "    <!-- è¾“å…¥æ¡† -->\n",
    "<div><form method=\"POST\" action=\"/QAbot\">\n",
    "    {% csrf_token %}\n",
    "    <label>\n",
    "        <input type=\"search\"  name=\"ques\" style=\"background-color:#ffffff;height:49px;width:700px;float:right\">\n",
    "    </label></form>\n",
    "</div>\n",
    "    <!-- åº•æ³¨ -->\n",
    "\t<div id=\"footer\" style=\"background-color:#FFA500;clear:both;text-align:center;\">\n",
    "ğŸ‘†è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
